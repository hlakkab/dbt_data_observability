{"creation_time": "2024-03-28T11:04:37+00:00", "days_back": 7, "models": {"model.proj.my_first_dbt_model": {"name": "my_first_dbt_model", "unique_id": "model.proj.my_first_dbt_model", "owners": [], "tags": [], "package_name": "proj", "description": "A starter dbt model", "full_path": "models/example/my_first_dbt_model.sql", "meta": {}, "materialization": "table", "database_name": "postgres", "schema_name": "public", "table_name": "my_first_dbt_model", "patch_path": "proj://models\\example\\schema.yml", "model_name": "my_first_dbt_model", "normalized_full_path": "proj/models/example/my_first_dbt_model.sql", "fqn": "postgres.public.my_first_dbt_model", "artifact_type": "model"}, "model.proj.my_second_dbt_model": {"name": "my_second_dbt_model", "unique_id": "model.proj.my_second_dbt_model", "owners": [], "tags": [], "package_name": "proj", "description": "A starter dbt model", "full_path": "models/example/my_second_dbt_model.sql", "meta": {}, "materialization": "view", "database_name": "postgres", "schema_name": "public", "table_name": "my_second_dbt_model", "patch_path": "proj://models\\example\\schema.yml", "model_name": "my_second_dbt_model", "normalized_full_path": "proj/models/example/my_second_dbt_model.sql", "fqn": "postgres.public.my_second_dbt_model", "artifact_type": "model"}, "model.proj.raw_orders": {"name": "raw_orders", "unique_id": "model.proj.raw_orders", "owners": [], "tags": [], "package_name": "proj", "description": "", "full_path": "models/example/raw_orders.sql", "meta": {}, "materialization": "view", "database_name": "postgres", "schema_name": "public", "table_name": "raw_orders", "patch_path": "proj://models\\example\\schema.yml", "model_name": "raw_orders", "normalized_full_path": "proj/models/example/raw_orders.sql", "fqn": "postgres.public.raw_orders", "artifact_type": "model"}, "model.proj.ref_raw_orders": {"name": "ref_raw_orders", "unique_id": "model.proj.ref_raw_orders", "owners": [], "tags": [], "package_name": "proj", "description": "", "full_path": "models/example/ref_raw_orders.sql", "meta": {}, "materialization": "view", "database_name": "postgres", "schema_name": "public", "table_name": "ref_raw_orders", "patch_path": null, "model_name": "ref_raw_orders", "normalized_full_path": "proj/models/example/ref_raw_orders.sql", "fqn": "postgres.public.ref_raw_orders", "artifact_type": "model"}, "source.proj.public.freshnes_test": {"name": "freshnes_test", "unique_id": "source.proj.public.freshnes_test", "owners": [], "tags": [], "package_name": "proj", "description": "", "full_path": "models/example/schema2.yml", "meta": {}, "materialization": null, "source_name": "public", "database_name": "postgres", "schema_name": "public", "table_name": "freshnes_test", "model_name": "freshnes_test", "normalized_full_path": "proj/models/example/schema2.yml", "fqn": "postgres.public.freshnes_test", "artifact_type": "source"}}, "groups": {"dbt": {"proj": {"models": {"example": {"__files__": [{"node_id": "model.proj.my_first_dbt_model", "resource_type": "model"}, {"node_id": "model.proj.my_second_dbt_model", "resource_type": "model"}, {"node_id": "model.proj.raw_orders", "resource_type": "model"}, {"node_id": "model.proj.ref_raw_orders", "resource_type": "model"}, {"node_id": "source.proj.public.freshnes_test", "resource_type": "source"}]}}}}, "tags": {"No tags": [{"node_id": "model.proj.my_first_dbt_model", "resource_type": "model"}, {"node_id": "model.proj.my_second_dbt_model", "resource_type": "model"}, {"node_id": "model.proj.raw_orders", "resource_type": "model"}, {"node_id": "model.proj.ref_raw_orders", "resource_type": "model"}, {"node_id": "source.proj.public.freshnes_test", "resource_type": "source"}]}, "owners": {"No owners": [{"node_id": "model.proj.my_first_dbt_model", "resource_type": "model"}, {"node_id": "model.proj.my_second_dbt_model", "resource_type": "model"}, {"node_id": "model.proj.raw_orders", "resource_type": "model"}, {"node_id": "model.proj.ref_raw_orders", "resource_type": "model"}, {"node_id": "source.proj.public.freshnes_test", "resource_type": "source"}]}}, "invocation": {"invocation_id": null, "detected_at": null, "command": null, "selected": null, "full_refresh": null, "job_url": null, "job_name": null, "job_id": null, "orchestrator": null}, "test_results": {"model.proj.my_first_dbt_model": [{"metadata": {"test_unique_id": "test.proj.unique_my_first_dbt_model_id.16e066b321", "elementary_unique_id": "test.proj.unique_my_first_dbt_model_id.16e066b321.id.generic", "database_name": "postgres", "schema_name": "public", "table_name": "my_first_dbt_model", "column_name": "id", "test_name": "unique", "test_display_name": "Unique", "latest_run_time": "2024-03-28T11:02:32+00:00", "latest_run_time_utc": "2024-03-28T11:02:32+00:00", "latest_run_status": "pass", "model_unique_id": "model.proj.my_first_dbt_model", "table_unique_id": "postgres.public.my_first_dbt_model", "test_type": "dbt_test", "test_sub_type": "generic", "test_query": "select\n    id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"public\".\"my_first_dbt_model\"\nwhere id is not null\ngroup by id\nhaving count(*) > 1", "test_params": {"column_name": "id", "model": "{{ get_where_subquery(ref('my_first_dbt_model')) }}"}, "test_created_at": null, "description": "This test validates that there are no duplicate values present in a field.", "result": {"result_description": null, "result_query": "select\n    id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"public\".\"my_first_dbt_model\"\nwhere id is not null\ngroup by id\nhaving count(*) > 1"}, "configuration": {"test_name": "unique", "test_params": {"column_name": "id", "model": "{{ get_where_subquery(ref('my_first_dbt_model')) }}"}}, "test_tags": []}, "test_results": {"display_name": "unique", "results_sample": null, "error_message": null, "failed_rows_count": -1}}], "model.proj.my_second_dbt_model": [{"metadata": {"test_unique_id": "test.proj.not_null_my_second_dbt_model_id.151b76d778", "elementary_unique_id": "test.proj.not_null_my_second_dbt_model_id.151b76d778.id.generic", "database_name": "postgres", "schema_name": "public", "table_name": "my_second_dbt_model", "column_name": "id", "test_name": "not_null", "test_display_name": "Not Null", "latest_run_time": "2024-03-28T11:02:31+00:00", "latest_run_time_utc": "2024-03-28T11:02:31+00:00", "latest_run_status": "pass", "model_unique_id": "model.proj.my_second_dbt_model", "table_unique_id": "postgres.public.my_second_dbt_model", "test_type": "dbt_test", "test_sub_type": "generic", "test_query": "select id\nfrom \"postgres\".\"public\".\"my_second_dbt_model\"\nwhere id is null", "test_params": {"column_name": "id", "model": "{{ get_where_subquery(ref('my_second_dbt_model')) }}"}, "test_created_at": null, "description": "This test validates that there are no `null` values present in a column.", "result": {"result_description": null, "result_query": "select id\nfrom \"postgres\".\"public\".\"my_second_dbt_model\"\nwhere id is null"}, "configuration": {"test_name": "not_null", "test_params": {"column_name": "id", "model": "{{ get_where_subquery(ref('my_second_dbt_model')) }}"}}, "test_tags": []}, "test_results": {"display_name": "not_null", "results_sample": null, "error_message": null, "failed_rows_count": -1}}, {"metadata": {"test_unique_id": "test.proj.unique_my_second_dbt_model_id.57a0f8c493", "elementary_unique_id": "test.proj.unique_my_second_dbt_model_id.57a0f8c493.id.generic", "database_name": "postgres", "schema_name": "public", "table_name": "my_second_dbt_model", "column_name": "id", "test_name": "unique", "test_display_name": "Unique", "latest_run_time": "2024-03-28T11:02:32+00:00", "latest_run_time_utc": "2024-03-28T11:02:32+00:00", "latest_run_status": "pass", "model_unique_id": "model.proj.my_second_dbt_model", "table_unique_id": "postgres.public.my_second_dbt_model", "test_type": "dbt_test", "test_sub_type": "generic", "test_query": "select\n    id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"public\".\"my_second_dbt_model\"\nwhere id is not null\ngroup by id\nhaving count(*) > 1", "test_params": {"column_name": "id", "model": "{{ get_where_subquery(ref('my_second_dbt_model')) }}"}, "test_created_at": null, "description": "This test validates that there are no duplicate values present in a field.", "result": {"result_description": null, "result_query": "select\n    id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"public\".\"my_second_dbt_model\"\nwhere id is not null\ngroup by id\nhaving count(*) > 1"}, "configuration": {"test_name": "unique", "test_params": {"column_name": "id", "model": "{{ get_where_subquery(ref('my_second_dbt_model')) }}"}}, "test_tags": []}, "test_results": {"display_name": "unique", "results_sample": null, "error_message": null, "failed_rows_count": -1}}], "model.proj.raw_orders": [{"metadata": {"test_unique_id": "test.proj.elementary_freshness_anomalies_raw_orders_creation_date.e113635563", "elementary_unique_id": "test.proj.elementary_freshness_anomalies_raw_orders_creation_date.e113635563.None.freshness", "database_name": "postgres", "schema_name": "public", "table_name": "raw_orders", "column_name": null, "test_name": "freshness_anomalies", "test_display_name": "Freshness Anomalies", "latest_run_time": "2024-03-28T11:02:31+00:00", "latest_run_time_utc": "2024-03-28T11:02:31+00:00", "latest_run_status": "pass", "model_unique_id": "model.proj.raw_orders", "table_unique_id": "postgres.public.raw_orders", "test_type": "anomaly_detection", "test_sub_type": "freshness", "test_query": "select * from (\n  \n  \n    \n        \n        \n\n        \n        \n        \n        \n\n        \n\n        \n\n        \n        \n        \n        \n\n        \n        \n        \n\n        \n        \n        \n        \n\n        \n\n        \n        \n        \n\n        \n        \n        \n        \n\n        \n        \n        \n        \n\n        with anomaly_scores as (\n        select\n            id,\n            metric_id,\n            test_execution_id,\n            test_unique_id,\n            detected_at,\n            full_table_name,\n            column_name,\n            metric_name,\n            anomaly_score,\n            anomaly_score_threshold,\n            anomalous_value,\n            bucket_start,\n            bucket_end,\n            bucket_seasonality,\n            metric_value,\n            min_metric_value,\n            max_metric_value,\n            training_avg,\n            training_stddev,\n            training_set_size,\n            training_start,\n            training_end,\n            dimension,\n            dimension_value,\n            \n    case\n        when dimension is not null then \n    'The last ' || metric_name || ' value for dimension ' || dimension || ' - ' ||\n    case when dimension_value is null then 'NULL' else dimension_value end || ' is ' || cast(round(cast(metric_value as numeric(28,6)), 3) as varchar(4096)) ||\n    '. The average for this metric is ' || cast(round(cast(training_avg as numeric(28,6)), 3) as varchar(4096)) || '.'\n\n        when metric_name = 'freshness' then \n    'Last update was at ' || anomalous_value || ', ' || cast(abs(round(cast(metric_value/3600 as numeric(28,6)), 2)) as varchar(4096)) || ' hours ago. Usually the table is updated within ' || cast(abs(round(cast(training_avg/3600 as numeric(28,6)), 2)) as varchar(4096)) || ' hours.'\n\n        when column_name is null then \n    'The last ' || metric_name || ' value is ' || cast(round(cast(metric_value as numeric(28,6)), 3) as varchar(4096)) ||\n    '. The average for this metric is ' || cast(round(cast(training_avg as numeric(28,6)), 3) as varchar(4096)) || '.'\n\n        when column_name is not null then \n    'In column ' || column_name || ', the last ' || metric_name || ' value is ' || cast(round(cast(metric_value as numeric(28,6)), 3) as varchar(4096)) ||\n    '. The average for this metric is ' || cast(round(cast(training_avg as numeric(28,6)), 3) as varchar(4096)) || '.'\n\n        else null\n    end as anomaly_description\n,\n            max(bucket_end) over (partition by test_execution_id) as max_bucket_end\n        from \"postgres\".\"public_elementary\".\"test_e113635563_eleme__anomaly_scores__tmp_20240328110231257585\"\n      ),\n      anomaly_scores_with_is_anomalous as (\n        select\n          *,\ncase when\n            anomaly_score is not null and\n            (\n              \n  (\n    metric_value = 0 and \n    \n      1 = 2\n    \n  )\n or\n              (\n                case when metric_name IN \n        ( 'freshness' ,  'event_freshness'  )\n then\n            anomaly_score > 3\n    else\n        \n        abs(anomaly_score) > 3\n    \n\n     end and\n                (\n  \n  \n  \n  \n    \n        (1 = 1)\n    \n\n    and\n\n    \n        (1 = 1)\n    \n  \n  )\n              )\n            ) and\n            bucket_end >= \n    cast(max_bucket_end as TIMESTAMP) + cast('-2' as INT) * INTERVAL '1 day'\n\n          then TRUE else FALSE end as is_anomalous\n        from anomaly_scores\n      )\n\n      select\n        metric_value as value,\n        training_avg as average,\n        \n        case\n        when is_anomalous = TRUE and 'both' = 'spike' then\n         lag(metric_value) over (partition by full_table_name, column_name, metric_name, dimension, dimension_value, bucket_seasonality order by bucket_end)\n        when is_anomalous = TRUE and 'both' != 'spike' then\n         lag(min_metric_value) over (partition by full_table_name, column_name, metric_name, dimension, dimension_value, bucket_seasonality order by bucket_end)\n        when 'both' = 'spike' then metric_value\n        else min_metric_value end as min_value,\n        case\n        when is_anomalous = TRUE and 'both' = 'drop' then\n         lag(metric_value) over (partition by full_table_name, column_name, metric_name, dimension, dimension_value, bucket_seasonality order by bucket_end)\n        when is_anomalous = TRUE and 'both' != 'drop' then\n         lag(max_metric_value) over (partition by full_table_name, column_name, metric_name, dimension, dimension_value, bucket_seasonality order by bucket_end)\n        when 'both' = 'drop' then metric_value\n        else max_metric_value end as max_value,\n        bucket_start as start_time,\n        bucket_end as end_time,\n        *\n      from anomaly_scores_with_is_anomalous\n      order by bucket_end, dimension_value\n    \n\n\n) results\n      where\n        anomaly_score is not null and\n        upper(full_table_name) = upper(cast('POSTGRES.PUBLIC.RAW_ORDERS' as varchar(4096))) and\n        metric_name = cast('freshness' as varchar(4096))", "test_params": {"timestamp_column": "creation_date", "model": "{{ get_where_subquery(ref('raw_orders')) }}", "where_expression": null, "anomaly_sensitivity": 3, "anomaly_direction": "both", "time_bucket": {"period": "day", "count": 1}, "days_back": 14, "backfill_days": 2, "seasonality": null, "freshness_column": null, "event_timestamp_column": null, "dimensions": null, "ignore_small_changes": {"spike_failure_percent_threshold": null, "drop_failure_percent_threshold": null}, "fail_on_zero": false, "detection_delay": {"period": "hour", "count": 0}, "anomaly_exclude_metrics": null}, "test_created_at": null, "description": "Monitors the freshness of your table over time, as the expected time between data updates.", "result": {"result_description": "Not enough data to calculate anomaly score.", "result_query": "select * from (\n  \n  \n    \n        \n        \n\n        \n        \n        \n        \n\n        \n\n        \n\n        \n        \n        \n        \n\n        \n        \n        \n\n        \n        \n        \n        \n\n        \n\n        \n        \n        \n\n        \n        \n        \n        \n\n        \n        \n        \n        \n\n        with anomaly_scores as (\n        select\n            id,\n            metric_id,\n            test_execution_id,\n            test_unique_id,\n            detected_at,\n            full_table_name,\n            column_name,\n            metric_name,\n            anomaly_score,\n            anomaly_score_threshold,\n            anomalous_value,\n            bucket_start,\n            bucket_end,\n            bucket_seasonality,\n            metric_value,\n            min_metric_value,\n            max_metric_value,\n            training_avg,\n            training_stddev,\n            training_set_size,\n            training_start,\n            training_end,\n            dimension,\n            dimension_value,\n            \n    case\n        when dimension is not null then \n    'The last ' || metric_name || ' value for dimension ' || dimension || ' - ' ||\n    case when dimension_value is null then 'NULL' else dimension_value end || ' is ' || cast(round(cast(metric_value as numeric(28,6)), 3) as varchar(4096)) ||\n    '. The average for this metric is ' || cast(round(cast(training_avg as numeric(28,6)), 3) as varchar(4096)) || '.'\n\n        when metric_name = 'freshness' then \n    'Last update was at ' || anomalous_value || ', ' || cast(abs(round(cast(metric_value/3600 as numeric(28,6)), 2)) as varchar(4096)) || ' hours ago. Usually the table is updated within ' || cast(abs(round(cast(training_avg/3600 as numeric(28,6)), 2)) as varchar(4096)) || ' hours.'\n\n        when column_name is null then \n    'The last ' || metric_name || ' value is ' || cast(round(cast(metric_value as numeric(28,6)), 3) as varchar(4096)) ||\n    '. The average for this metric is ' || cast(round(cast(training_avg as numeric(28,6)), 3) as varchar(4096)) || '.'\n\n        when column_name is not null then \n    'In column ' || column_name || ', the last ' || metric_name || ' value is ' || cast(round(cast(metric_value as numeric(28,6)), 3) as varchar(4096)) ||\n    '. The average for this metric is ' || cast(round(cast(training_avg as numeric(28,6)), 3) as varchar(4096)) || '.'\n\n        else null\n    end as anomaly_description\n,\n            max(bucket_end) over (partition by test_execution_id) as max_bucket_end\n        from \"postgres\".\"public_elementary\".\"test_e113635563_eleme__anomaly_scores__tmp_20240328110231257585\"\n      ),\n      anomaly_scores_with_is_anomalous as (\n        select\n          *,\ncase when\n            anomaly_score is not null and\n            (\n              \n  (\n    metric_value = 0 and \n    \n      1 = 2\n    \n  )\n or\n              (\n                case when metric_name IN \n        ( 'freshness' ,  'event_freshness'  )\n then\n            anomaly_score > 3\n    else\n        \n        abs(anomaly_score) > 3\n    \n\n     end and\n                (\n  \n  \n  \n  \n    \n        (1 = 1)\n    \n\n    and\n\n    \n        (1 = 1)\n    \n  \n  )\n              )\n            ) and\n            bucket_end >= \n    cast(max_bucket_end as TIMESTAMP) + cast('-2' as INT) * INTERVAL '1 day'\n\n          then TRUE else FALSE end as is_anomalous\n        from anomaly_scores\n      )\n\n      select\n        metric_value as value,\n        training_avg as average,\n        \n        case\n        when is_anomalous = TRUE and 'both' = 'spike' then\n         lag(metric_value) over (partition by full_table_name, column_name, metric_name, dimension, dimension_value, bucket_seasonality order by bucket_end)\n        when is_anomalous = TRUE and 'both' != 'spike' then\n         lag(min_metric_value) over (partition by full_table_name, column_name, metric_name, dimension, dimension_value, bucket_seasonality order by bucket_end)\n        when 'both' = 'spike' then metric_value\n        else min_metric_value end as min_value,\n        case\n        when is_anomalous = TRUE and 'both' = 'drop' then\n         lag(metric_value) over (partition by full_table_name, column_name, metric_name, dimension, dimension_value, bucket_seasonality order by bucket_end)\n        when is_anomalous = TRUE and 'both' != 'drop' then\n         lag(max_metric_value) over (partition by full_table_name, column_name, metric_name, dimension, dimension_value, bucket_seasonality order by bucket_end)\n        when 'both' = 'drop' then metric_value\n        else max_metric_value end as max_value,\n        bucket_start as start_time,\n        bucket_end as end_time,\n        *\n      from anomaly_scores_with_is_anomalous\n      order by bucket_end, dimension_value\n    \n\n\n) results\n      where\n        anomaly_score is not null and\n        upper(full_table_name) = upper(cast('POSTGRES.PUBLIC.RAW_ORDERS' as varchar(4096))) and\n        metric_name = cast('freshness' as varchar(4096))"}, "configuration": {"test_name": "freshness_anomalies", "timestamp_column": "creation_date", "testing_timeframe": "1 day", "anomaly_threshold": 3}, "test_tags": ["elementary-tests"]}, "test_results": {"display_name": "Freshness", "metrics": [], "result_description": "Not enough data to calculate anomaly score."}}, {"metadata": {"test_unique_id": "test.proj.not_null_raw_orders_creation_date.87e59d0c4c", "elementary_unique_id": "test.proj.not_null_raw_orders_creation_date.87e59d0c4c.creation_date.generic", "database_name": "postgres", "schema_name": "public", "table_name": "raw_orders", "column_name": "creation_date", "test_name": "not_null", "test_display_name": "Not Null", "latest_run_time": "2024-03-28T11:02:32+00:00", "latest_run_time_utc": "2024-03-28T11:02:32+00:00", "latest_run_status": "pass", "model_unique_id": "model.proj.raw_orders", "table_unique_id": "postgres.public.raw_orders", "test_type": "dbt_test", "test_sub_type": "generic", "test_query": "select creation_date\nfrom \"postgres\".\"public\".\"raw_orders\"\nwhere creation_date is null", "test_params": {"column_name": "creation_date", "model": "{{ get_where_subquery(ref('raw_orders')) }}"}, "test_created_at": null, "description": "This test validates that there are no `null` values present in a column.", "result": {"result_description": null, "result_query": "select creation_date\nfrom \"postgres\".\"public\".\"raw_orders\"\nwhere creation_date is null"}, "configuration": {"test_name": "not_null", "test_params": {"column_name": "creation_date", "model": "{{ get_where_subquery(ref('raw_orders')) }}"}}, "test_tags": []}, "test_results": {"display_name": "not_null", "results_sample": null, "error_message": null, "failed_rows_count": -1}}]}, "test_results_totals": {"model.proj.my_first_dbt_model": {"errors": 0, "warnings": 0, "passed": 1, "failures": 0}, "model.proj.my_second_dbt_model": {"errors": 0, "warnings": 0, "passed": 2, "failures": 0}, "model.proj.raw_orders": {"errors": 0, "warnings": 0, "passed": 2, "failures": 0}}, "test_runs": {"model.proj.my_first_dbt_model": [{"metadata": {"test_unique_id": "test.proj.unique_my_first_dbt_model_id.16e066b321", "elementary_unique_id": "test.proj.unique_my_first_dbt_model_id.16e066b321.id.generic", "database_name": "postgres", "schema_name": "public", "table_name": "my_first_dbt_model", "column_name": "id", "test_name": "unique", "test_display_name": "Unique", "latest_run_time": "2024-03-28T11:02:32+00:00", "latest_run_time_utc": "2024-03-28T11:02:32+00:00", "latest_run_status": "pass", "model_unique_id": "model.proj.my_first_dbt_model", "table_unique_id": "postgres.public.my_first_dbt_model", "test_type": "dbt_test", "test_sub_type": "generic", "test_query": "select\n    id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"public\".\"my_first_dbt_model\"\nwhere id is not null\ngroup by id\nhaving count(*) > 1", "test_params": {"column_name": "id", "model": "{{ get_where_subquery(ref('my_first_dbt_model')) }}"}, "test_created_at": null, "description": "This test validates that there are no duplicate values present in a field.", "result": {"result_description": null, "result_query": "select\n    id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"public\".\"my_first_dbt_model\"\nwhere id is not null\ngroup by id\nhaving count(*) > 1"}, "configuration": {"test_name": "unique", "test_params": {"column_name": "id", "model": "{{ get_where_subquery(ref('my_first_dbt_model')) }}"}}, "test_tags": []}, "test_runs": {"fail_rate": 0.0, "totals": {"errors": 0, "warnings": 0, "passed": 4, "failures": 0}, "invocations": [{"affected_rows": null, "time_utc": "2024-03-27T17:54:16+00:00", "id": "e3fcf36a-db2c-4d89-941e-69a7fe5601f9", "status": "pass"}, {"affected_rows": null, "time_utc": "2024-03-28T09:46:39+00:00", "id": "d3eba6b8-9592-4c85-b09a-8def2f142e0b", "status": "pass"}, {"affected_rows": null, "time_utc": "2024-03-28T10:36:40+00:00", "id": "7648c902-2317-49d4-9349-bce979facf79", "status": "pass"}, {"affected_rows": null, "time_utc": "2024-03-28T11:02:32+00:00", "id": "f0197411-26d1-4876-aec9-d7530949b617", "status": "pass"}], "description": "There were no failures, no errors and no warnings on the last 4 test runs."}}], "model.proj.my_second_dbt_model": [{"metadata": {"test_unique_id": "test.proj.not_null_my_second_dbt_model_id.151b76d778", "elementary_unique_id": "test.proj.not_null_my_second_dbt_model_id.151b76d778.id.generic", "database_name": "postgres", "schema_name": "public", "table_name": "my_second_dbt_model", "column_name": "id", "test_name": "not_null", "test_display_name": "Not Null", "latest_run_time": "2024-03-28T11:02:31+00:00", "latest_run_time_utc": "2024-03-28T11:02:31+00:00", "latest_run_status": "pass", "model_unique_id": "model.proj.my_second_dbt_model", "table_unique_id": "postgres.public.my_second_dbt_model", "test_type": "dbt_test", "test_sub_type": "generic", "test_query": "select id\nfrom \"postgres\".\"public\".\"my_second_dbt_model\"\nwhere id is null", "test_params": {"column_name": "id", "model": "{{ get_where_subquery(ref('my_second_dbt_model')) }}"}, "test_created_at": null, "description": "This test validates that there are no `null` values present in a column.", "result": {"result_description": null, "result_query": "select id\nfrom \"postgres\".\"public\".\"my_second_dbt_model\"\nwhere id is null"}, "configuration": {"test_name": "not_null", "test_params": {"column_name": "id", "model": "{{ get_where_subquery(ref('my_second_dbt_model')) }}"}}, "test_tags": []}, "test_runs": {"fail_rate": 0.0, "totals": {"errors": 0, "warnings": 0, "passed": 4, "failures": 0}, "invocations": [{"affected_rows": null, "time_utc": "2024-03-27T17:54:16+00:00", "id": "e3fcf36a-db2c-4d89-941e-69a7fe5601f9", "status": "pass"}, {"affected_rows": null, "time_utc": "2024-03-28T09:46:38+00:00", "id": "d3eba6b8-9592-4c85-b09a-8def2f142e0b", "status": "pass"}, {"affected_rows": null, "time_utc": "2024-03-28T10:36:40+00:00", "id": "7648c902-2317-49d4-9349-bce979facf79", "status": "pass"}, {"affected_rows": null, "time_utc": "2024-03-28T11:02:31+00:00", "id": "f0197411-26d1-4876-aec9-d7530949b617", "status": "pass"}], "description": "There were no failures, no errors and no warnings on the last 4 test runs."}}, {"metadata": {"test_unique_id": "test.proj.unique_my_second_dbt_model_id.57a0f8c493", "elementary_unique_id": "test.proj.unique_my_second_dbt_model_id.57a0f8c493.id.generic", "database_name": "postgres", "schema_name": "public", "table_name": "my_second_dbt_model", "column_name": "id", "test_name": "unique", "test_display_name": "Unique", "latest_run_time": "2024-03-28T11:02:32+00:00", "latest_run_time_utc": "2024-03-28T11:02:32+00:00", "latest_run_status": "pass", "model_unique_id": "model.proj.my_second_dbt_model", "table_unique_id": "postgres.public.my_second_dbt_model", "test_type": "dbt_test", "test_sub_type": "generic", "test_query": "select\n    id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"public\".\"my_second_dbt_model\"\nwhere id is not null\ngroup by id\nhaving count(*) > 1", "test_params": {"column_name": "id", "model": "{{ get_where_subquery(ref('my_second_dbt_model')) }}"}, "test_created_at": null, "description": "This test validates that there are no duplicate values present in a field.", "result": {"result_description": null, "result_query": "select\n    id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"public\".\"my_second_dbt_model\"\nwhere id is not null\ngroup by id\nhaving count(*) > 1"}, "configuration": {"test_name": "unique", "test_params": {"column_name": "id", "model": "{{ get_where_subquery(ref('my_second_dbt_model')) }}"}}, "test_tags": []}, "test_runs": {"fail_rate": 0.0, "totals": {"errors": 0, "warnings": 0, "passed": 4, "failures": 0}, "invocations": [{"affected_rows": null, "time_utc": "2024-03-27T17:54:16+00:00", "id": "e3fcf36a-db2c-4d89-941e-69a7fe5601f9", "status": "pass"}, {"affected_rows": null, "time_utc": "2024-03-28T09:46:39+00:00", "id": "d3eba6b8-9592-4c85-b09a-8def2f142e0b", "status": "pass"}, {"affected_rows": null, "time_utc": "2024-03-28T10:36:40+00:00", "id": "7648c902-2317-49d4-9349-bce979facf79", "status": "pass"}, {"affected_rows": null, "time_utc": "2024-03-28T11:02:32+00:00", "id": "f0197411-26d1-4876-aec9-d7530949b617", "status": "pass"}], "description": "There were no failures, no errors and no warnings on the last 4 test runs."}}], "model.proj.raw_orders": [{"metadata": {"test_unique_id": "test.proj.elementary_freshness_anomalies_raw_orders_creation_date.e113635563", "elementary_unique_id": "test.proj.elementary_freshness_anomalies_raw_orders_creation_date.e113635563.None.freshness", "database_name": "postgres", "schema_name": "public", "table_name": "raw_orders", "column_name": null, "test_name": "freshness_anomalies", "test_display_name": "Freshness Anomalies", "latest_run_time": "2024-03-28T11:02:31+00:00", "latest_run_time_utc": "2024-03-28T11:02:31+00:00", "latest_run_status": "pass", "model_unique_id": "model.proj.raw_orders", "table_unique_id": "postgres.public.raw_orders", "test_type": "anomaly_detection", "test_sub_type": "freshness", "test_query": "select * from (\n  \n  \n    \n        \n        \n\n        \n        \n        \n        \n\n        \n\n        \n\n        \n        \n        \n        \n\n        \n        \n        \n\n        \n        \n        \n        \n\n        \n\n        \n        \n        \n\n        \n        \n        \n        \n\n        \n        \n        \n        \n\n        with anomaly_scores as (\n        select\n            id,\n            metric_id,\n            test_execution_id,\n            test_unique_id,\n            detected_at,\n            full_table_name,\n            column_name,\n            metric_name,\n            anomaly_score,\n            anomaly_score_threshold,\n            anomalous_value,\n            bucket_start,\n            bucket_end,\n            bucket_seasonality,\n            metric_value,\n            min_metric_value,\n            max_metric_value,\n            training_avg,\n            training_stddev,\n            training_set_size,\n            training_start,\n            training_end,\n            dimension,\n            dimension_value,\n            \n    case\n        when dimension is not null then \n    'The last ' || metric_name || ' value for dimension ' || dimension || ' - ' ||\n    case when dimension_value is null then 'NULL' else dimension_value end || ' is ' || cast(round(cast(metric_value as numeric(28,6)), 3) as varchar(4096)) ||\n    '. The average for this metric is ' || cast(round(cast(training_avg as numeric(28,6)), 3) as varchar(4096)) || '.'\n\n        when metric_name = 'freshness' then \n    'Last update was at ' || anomalous_value || ', ' || cast(abs(round(cast(metric_value/3600 as numeric(28,6)), 2)) as varchar(4096)) || ' hours ago. Usually the table is updated within ' || cast(abs(round(cast(training_avg/3600 as numeric(28,6)), 2)) as varchar(4096)) || ' hours.'\n\n        when column_name is null then \n    'The last ' || metric_name || ' value is ' || cast(round(cast(metric_value as numeric(28,6)), 3) as varchar(4096)) ||\n    '. The average for this metric is ' || cast(round(cast(training_avg as numeric(28,6)), 3) as varchar(4096)) || '.'\n\n        when column_name is not null then \n    'In column ' || column_name || ', the last ' || metric_name || ' value is ' || cast(round(cast(metric_value as numeric(28,6)), 3) as varchar(4096)) ||\n    '. The average for this metric is ' || cast(round(cast(training_avg as numeric(28,6)), 3) as varchar(4096)) || '.'\n\n        else null\n    end as anomaly_description\n,\n            max(bucket_end) over (partition by test_execution_id) as max_bucket_end\n        from \"postgres\".\"public_elementary\".\"test_e113635563_eleme__anomaly_scores__tmp_20240328110231257585\"\n      ),\n      anomaly_scores_with_is_anomalous as (\n        select\n          *,\ncase when\n            anomaly_score is not null and\n            (\n              \n  (\n    metric_value = 0 and \n    \n      1 = 2\n    \n  )\n or\n              (\n                case when metric_name IN \n        ( 'freshness' ,  'event_freshness'  )\n then\n            anomaly_score > 3\n    else\n        \n        abs(anomaly_score) > 3\n    \n\n     end and\n                (\n  \n  \n  \n  \n    \n        (1 = 1)\n    \n\n    and\n\n    \n        (1 = 1)\n    \n  \n  )\n              )\n            ) and\n            bucket_end >= \n    cast(max_bucket_end as TIMESTAMP) + cast('-2' as INT) * INTERVAL '1 day'\n\n          then TRUE else FALSE end as is_anomalous\n        from anomaly_scores\n      )\n\n      select\n        metric_value as value,\n        training_avg as average,\n        \n        case\n        when is_anomalous = TRUE and 'both' = 'spike' then\n         lag(metric_value) over (partition by full_table_name, column_name, metric_name, dimension, dimension_value, bucket_seasonality order by bucket_end)\n        when is_anomalous = TRUE and 'both' != 'spike' then\n         lag(min_metric_value) over (partition by full_table_name, column_name, metric_name, dimension, dimension_value, bucket_seasonality order by bucket_end)\n        when 'both' = 'spike' then metric_value\n        else min_metric_value end as min_value,\n        case\n        when is_anomalous = TRUE and 'both' = 'drop' then\n         lag(metric_value) over (partition by full_table_name, column_name, metric_name, dimension, dimension_value, bucket_seasonality order by bucket_end)\n        when is_anomalous = TRUE and 'both' != 'drop' then\n         lag(max_metric_value) over (partition by full_table_name, column_name, metric_name, dimension, dimension_value, bucket_seasonality order by bucket_end)\n        when 'both' = 'drop' then metric_value\n        else max_metric_value end as max_value,\n        bucket_start as start_time,\n        bucket_end as end_time,\n        *\n      from anomaly_scores_with_is_anomalous\n      order by bucket_end, dimension_value\n    \n\n\n) results\n      where\n        anomaly_score is not null and\n        upper(full_table_name) = upper(cast('POSTGRES.PUBLIC.RAW_ORDERS' as varchar(4096))) and\n        metric_name = cast('freshness' as varchar(4096))", "test_params": {"timestamp_column": "creation_date", "model": "{{ get_where_subquery(ref('raw_orders')) }}", "where_expression": null, "anomaly_sensitivity": 3, "anomaly_direction": "both", "time_bucket": {"period": "day", "count": 1}, "days_back": 14, "backfill_days": 2, "seasonality": null, "freshness_column": null, "event_timestamp_column": null, "dimensions": null, "ignore_small_changes": {"spike_failure_percent_threshold": null, "drop_failure_percent_threshold": null}, "fail_on_zero": false, "detection_delay": {"period": "hour", "count": 0}, "anomaly_exclude_metrics": null}, "test_created_at": null, "description": "Monitors the freshness of your table over time, as the expected time between data updates.", "result": {"result_description": "Not enough data to calculate anomaly score.", "result_query": "select * from (\n  \n  \n    \n        \n        \n\n        \n        \n        \n        \n\n        \n\n        \n\n        \n        \n        \n        \n\n        \n        \n        \n\n        \n        \n        \n        \n\n        \n\n        \n        \n        \n\n        \n        \n        \n        \n\n        \n        \n        \n        \n\n        with anomaly_scores as (\n        select\n            id,\n            metric_id,\n            test_execution_id,\n            test_unique_id,\n            detected_at,\n            full_table_name,\n            column_name,\n            metric_name,\n            anomaly_score,\n            anomaly_score_threshold,\n            anomalous_value,\n            bucket_start,\n            bucket_end,\n            bucket_seasonality,\n            metric_value,\n            min_metric_value,\n            max_metric_value,\n            training_avg,\n            training_stddev,\n            training_set_size,\n            training_start,\n            training_end,\n            dimension,\n            dimension_value,\n            \n    case\n        when dimension is not null then \n    'The last ' || metric_name || ' value for dimension ' || dimension || ' - ' ||\n    case when dimension_value is null then 'NULL' else dimension_value end || ' is ' || cast(round(cast(metric_value as numeric(28,6)), 3) as varchar(4096)) ||\n    '. The average for this metric is ' || cast(round(cast(training_avg as numeric(28,6)), 3) as varchar(4096)) || '.'\n\n        when metric_name = 'freshness' then \n    'Last update was at ' || anomalous_value || ', ' || cast(abs(round(cast(metric_value/3600 as numeric(28,6)), 2)) as varchar(4096)) || ' hours ago. Usually the table is updated within ' || cast(abs(round(cast(training_avg/3600 as numeric(28,6)), 2)) as varchar(4096)) || ' hours.'\n\n        when column_name is null then \n    'The last ' || metric_name || ' value is ' || cast(round(cast(metric_value as numeric(28,6)), 3) as varchar(4096)) ||\n    '. The average for this metric is ' || cast(round(cast(training_avg as numeric(28,6)), 3) as varchar(4096)) || '.'\n\n        when column_name is not null then \n    'In column ' || column_name || ', the last ' || metric_name || ' value is ' || cast(round(cast(metric_value as numeric(28,6)), 3) as varchar(4096)) ||\n    '. The average for this metric is ' || cast(round(cast(training_avg as numeric(28,6)), 3) as varchar(4096)) || '.'\n\n        else null\n    end as anomaly_description\n,\n            max(bucket_end) over (partition by test_execution_id) as max_bucket_end\n        from \"postgres\".\"public_elementary\".\"test_e113635563_eleme__anomaly_scores__tmp_20240328110231257585\"\n      ),\n      anomaly_scores_with_is_anomalous as (\n        select\n          *,\ncase when\n            anomaly_score is not null and\n            (\n              \n  (\n    metric_value = 0 and \n    \n      1 = 2\n    \n  )\n or\n              (\n                case when metric_name IN \n        ( 'freshness' ,  'event_freshness'  )\n then\n            anomaly_score > 3\n    else\n        \n        abs(anomaly_score) > 3\n    \n\n     end and\n                (\n  \n  \n  \n  \n    \n        (1 = 1)\n    \n\n    and\n\n    \n        (1 = 1)\n    \n  \n  )\n              )\n            ) and\n            bucket_end >= \n    cast(max_bucket_end as TIMESTAMP) + cast('-2' as INT) * INTERVAL '1 day'\n\n          then TRUE else FALSE end as is_anomalous\n        from anomaly_scores\n      )\n\n      select\n        metric_value as value,\n        training_avg as average,\n        \n        case\n        when is_anomalous = TRUE and 'both' = 'spike' then\n         lag(metric_value) over (partition by full_table_name, column_name, metric_name, dimension, dimension_value, bucket_seasonality order by bucket_end)\n        when is_anomalous = TRUE and 'both' != 'spike' then\n         lag(min_metric_value) over (partition by full_table_name, column_name, metric_name, dimension, dimension_value, bucket_seasonality order by bucket_end)\n        when 'both' = 'spike' then metric_value\n        else min_metric_value end as min_value,\n        case\n        when is_anomalous = TRUE and 'both' = 'drop' then\n         lag(metric_value) over (partition by full_table_name, column_name, metric_name, dimension, dimension_value, bucket_seasonality order by bucket_end)\n        when is_anomalous = TRUE and 'both' != 'drop' then\n         lag(max_metric_value) over (partition by full_table_name, column_name, metric_name, dimension, dimension_value, bucket_seasonality order by bucket_end)\n        when 'both' = 'drop' then metric_value\n        else max_metric_value end as max_value,\n        bucket_start as start_time,\n        bucket_end as end_time,\n        *\n      from anomaly_scores_with_is_anomalous\n      order by bucket_end, dimension_value\n    \n\n\n) results\n      where\n        anomaly_score is not null and\n        upper(full_table_name) = upper(cast('POSTGRES.PUBLIC.RAW_ORDERS' as varchar(4096))) and\n        metric_name = cast('freshness' as varchar(4096))"}, "configuration": {"test_name": "freshness_anomalies", "timestamp_column": "creation_date", "testing_timeframe": "1 day", "anomaly_threshold": 3}, "test_tags": ["elementary-tests"]}, "test_runs": {"fail_rate": 0.0, "totals": {"errors": 0, "warnings": 0, "passed": 2, "failures": 0}, "invocations": [{"affected_rows": null, "time_utc": "2024-03-28T10:36:39+00:00", "id": "7648c902-2317-49d4-9349-bce979facf79", "status": "pass"}, {"affected_rows": null, "time_utc": "2024-03-28T11:02:31+00:00", "id": "f0197411-26d1-4876-aec9-d7530949b617", "status": "pass"}], "description": "There were no failures, no errors and no warnings on the last 2 test runs."}}, {"metadata": {"test_unique_id": "test.proj.not_null_raw_orders_creation_date.87e59d0c4c", "elementary_unique_id": "test.proj.not_null_raw_orders_creation_date.87e59d0c4c.creation_date.generic", "database_name": "postgres", "schema_name": "public", "table_name": "raw_orders", "column_name": "creation_date", "test_name": "not_null", "test_display_name": "Not Null", "latest_run_time": "2024-03-28T11:02:32+00:00", "latest_run_time_utc": "2024-03-28T11:02:32+00:00", "latest_run_status": "pass", "model_unique_id": "model.proj.raw_orders", "table_unique_id": "postgres.public.raw_orders", "test_type": "dbt_test", "test_sub_type": "generic", "test_query": "select creation_date\nfrom \"postgres\".\"public\".\"raw_orders\"\nwhere creation_date is null", "test_params": {"column_name": "creation_date", "model": "{{ get_where_subquery(ref('raw_orders')) }}"}, "test_created_at": null, "description": "This test validates that there are no `null` values present in a column.", "result": {"result_description": null, "result_query": "select creation_date\nfrom \"postgres\".\"public\".\"raw_orders\"\nwhere creation_date is null"}, "configuration": {"test_name": "not_null", "test_params": {"column_name": "creation_date", "model": "{{ get_where_subquery(ref('raw_orders')) }}"}}, "test_tags": []}, "test_runs": {"fail_rate": 0.0, "totals": {"errors": 0, "warnings": 0, "passed": 4, "failures": 0}, "invocations": [{"affected_rows": null, "time_utc": "2024-03-27T17:54:16+00:00", "id": "e3fcf36a-db2c-4d89-941e-69a7fe5601f9", "status": "pass"}, {"affected_rows": null, "time_utc": "2024-03-28T09:46:39+00:00", "id": "d3eba6b8-9592-4c85-b09a-8def2f142e0b", "status": "pass"}, {"affected_rows": null, "time_utc": "2024-03-28T10:36:40+00:00", "id": "7648c902-2317-49d4-9349-bce979facf79", "status": "pass"}, {"affected_rows": null, "time_utc": "2024-03-28T11:02:32+00:00", "id": "f0197411-26d1-4876-aec9-d7530949b617", "status": "pass"}], "description": "There were no failures, no errors and no warnings on the last 4 test runs."}}]}, "test_runs_totals": {"model.proj.my_first_dbt_model": {"errors": 0, "warnings": 0, "passed": 4, "failures": 0}, "model.proj.my_second_dbt_model": {"errors": 0, "warnings": 0, "passed": 8, "failures": 0}, "model.proj.raw_orders": {"errors": 0, "warnings": 0, "passed": 6, "failures": 0}}, "coverages": {"model.proj.my_first_dbt_model": {"table_tests": 0, "column_tests": 1}, "model.proj.my_second_dbt_model": {"table_tests": 0, "column_tests": 2}, "model.proj.raw_orders": {"table_tests": 1, "column_tests": 1}}, "model_runs": [{"unique_id": "model.proj.my_first_dbt_model", "schema": "public", "name": "my_first_dbt_model", "status": "success", "last_exec_time": 0.6, "median_exec_time": 0.4, "compiled_code": "/*\n    Welcome to your first dbt model!\n    Did you know that you can also configure models directly within SQL files?\n    This will override configurations stated in dbt_project.yml\n\n    Try changing \"table\" to \"view\" below\n*/\n\n\n\nwith source_data as (\n\n    select 1 as id\n    union all\n    select null as id\n\n)\n\nselect *\nfrom source_data\n\n/*\n    Uncomment the line below to remove records with null `id` values\n*/\n\n-- where id is not null", "last_generated_at": "2024-03-28T09:46:02+00:00", "exec_time_change_rate": 49.99999999999998, "totals": {"errors": 0, "success": 2}, "runs": [{"id": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "time_utc": "2024-03-27T17:52:45+00:00", "status": "success", "full_refresh": false, "materialization": "table", "execution_time": 0.2}, {"id": "47dded33-8154-488c-9359-a11260849c19", "time_utc": "2024-03-28T09:46:02+00:00", "status": "success", "full_refresh": false, "materialization": "table", "execution_time": 0.6}]}, {"unique_id": "model.proj.ref_raw_orders", "schema": "public", "name": "ref_raw_orders", "status": "success", "last_exec_time": 0.3, "median_exec_time": 0.3, "compiled_code": "with payments as (\r\n    select * from public.freshnes_test\r\n),\r\nfinal as (\r\n    select\r\n        user,\r\n        creation_date\r\n    from payments\r\n)\r\nselect * from final", "last_generated_at": "2024-03-27T17:52:45+00:00", "exec_time_change_rate": 0.0, "totals": {"errors": 0, "success": 1}, "runs": [{"id": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "time_utc": "2024-03-27T17:52:45+00:00", "status": "success", "full_refresh": false, "materialization": "view", "execution_time": 0.3}]}, {"unique_id": "model.proj.my_second_dbt_model", "schema": "public", "name": "my_second_dbt_model", "status": "success", "last_exec_time": 0.3, "median_exec_time": 0.2, "compiled_code": "-- Use the `ref` function to select from other models\n\nselect *\nfrom \"postgres\".\"public\".\"my_first_dbt_model\"\nwhere id = 1", "last_generated_at": "2024-03-28T09:46:02+00:00", "exec_time_change_rate": 49.99999999999998, "totals": {"errors": 0, "success": 2}, "runs": [{"id": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "time_utc": "2024-03-27T17:52:45+00:00", "status": "success", "full_refresh": false, "materialization": "view", "execution_time": 0.1}, {"id": "47dded33-8154-488c-9359-a11260849c19", "time_utc": "2024-03-28T09:46:02+00:00", "status": "success", "full_refresh": false, "materialization": "view", "execution_time": 0.3}]}, {"unique_id": "model.proj.raw_orders", "schema": "public", "name": "raw_orders", "status": "success", "last_exec_time": 0.1, "median_exec_time": 0.1, "compiled_code": "select *\nfrom \"postgres\".\"public\".\"ref_raw_orders\"", "last_generated_at": "2024-03-27T17:52:45+00:00", "exec_time_change_rate": 0.0, "totals": {"errors": 0, "success": 1}, "runs": [{"id": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "time_utc": "2024-03-27T17:52:45+00:00", "status": "success", "full_refresh": false, "materialization": "view", "execution_time": 0.1}]}], "model_runs_totals": {"model.proj.my_first_dbt_model": {"errors": 0, "warnings": 0, "passed": 2, "failures": 0}, "model.proj.ref_raw_orders": {"errors": 0, "warnings": 0, "passed": 1, "failures": 0}, "model.proj.my_second_dbt_model": {"errors": 0, "warnings": 0, "passed": 2, "failures": 0}, "model.proj.raw_orders": {"errors": 0, "warnings": 0, "passed": 1, "failures": 0}}, "filters": {"test_results": [{"name": "passed", "display_name": "Passed", "model_unique_ids": ["model.proj.my_first_dbt_model", "model.proj.my_second_dbt_model", "model.proj.raw_orders"]}, {"name": "no_test", "display_name": "No Tests", "model_unique_ids": ["model.proj.ref_raw_orders", "source.proj.public.freshnes_test"]}], "test_runs": [{"name": "passed", "display_name": "Passed", "model_unique_ids": ["model.proj.my_first_dbt_model", "model.proj.my_second_dbt_model", "model.proj.raw_orders"]}, {"name": "no_test", "display_name": "No Tests", "model_unique_ids": ["model.proj.ref_raw_orders", "source.proj.public.freshnes_test"]}], "model_runs": [{"name": "success", "display_name": "Successful Runs", "model_unique_ids": ["model.proj.my_first_dbt_model", "model.proj.ref_raw_orders", "model.proj.raw_orders", "model.proj.my_second_dbt_model"]}]}, "lineage": {"nodes": [{"id": "model.proj.my_first_dbt_model", "type": "model", "sub_type": "table"}, {"id": "model.proj.my_second_dbt_model", "type": "model", "sub_type": "view"}, {"id": "model.proj.raw_orders", "type": "model", "sub_type": "view"}, {"id": "model.proj.ref_raw_orders", "type": "model", "sub_type": "view"}, {"id": "source.proj.public.freshnes_test", "type": "source", "sub_type": null}], "edges": [["model.proj.my_second_dbt_model", "model.proj.my_first_dbt_model"], ["model.proj.raw_orders", "model.proj.ref_raw_orders"]]}, "invocations": [{"invocation_id": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "detected_at": null, "command": "run", "selected": "", "full_refresh": false, "job_url": null, "job_name": null, "job_id": null, "orchestrator": null}, {"invocation_id": "47dded33-8154-488c-9359-a11260849c19", "detected_at": null, "command": "run", "selected": "my_first_dbt_model my_second_dbt_model", "full_refresh": false, "job_url": "None/dags/None/grid", "job_name": null, "job_id": null, "orchestrator": "airflow"}], "resources_latest_invocation": {"model.elementary.alerts_anomaly_detection": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.alerts_dbt_models": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.alerts_dbt_source_freshness": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.alerts_dbt_tests": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.alerts_schema_changes": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.anomaly_threshold_sensitivity": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.data_monitoring_metrics": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.dbt_artifacts_hashes": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.dbt_columns": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.dbt_exposures": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.dbt_invocations": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.dbt_metrics": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.dbt_models": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.dbt_run_results": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.dbt_seeds": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.dbt_snapshots": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.dbt_source_freshness_results": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.dbt_sources": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.dbt_tests": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.elementary_test_results": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.enriched_columns": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.information_schema_columns": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.job_run_results": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.metadata": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.metrics_anomaly_score": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.model_run_results": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.monitors_runs": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.schema_columns_snapshot": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.snapshot_run_results": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.elementary.test_result_rows": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.proj.my_first_dbt_model": "47dded33-8154-488c-9359-a11260849c19", "model.proj.my_second_dbt_model": "47dded33-8154-488c-9359-a11260849c19", "model.proj.raw_orders": "7c40e064-8b08-4dc9-bcad-539712e8ab11", "model.proj.ref_raw_orders": "7c40e064-8b08-4dc9-bcad-539712e8ab11"}, "invocations_job_identification": {}, "env": {"project_name": "proj", "env": "dev", "warehouse_type": "postgres"}, "tracking": {"posthog_api_key": "phc_56XBEzZmh02mGkadqLiYW51eECyYKWPyecVwkGdGUfg", "report_generator_anonymous_user_id": "2a23c4f2-4b8c-41f8-a3c4-dd9be27bfd13", "anonymous_warehouse_id": "49960de5880e8c687434170f6476605b8fe4aeb9a28632c7995cf3ba831d9763"}}